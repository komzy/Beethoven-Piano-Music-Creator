{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark with ML-Week 1 Assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObsaGmHftbzXUDH3fl/zSm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komzy/Beethoven-Piano-Music-Creator/blob/master/week1/Spark_with_ML_Week_1_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RJhopfhJLGS"
      },
      "source": [
        "Part A: Homework/Assignment\n",
        "Data : https://opendata.com.pk/dataset/corona-virus-pakistan-dataset-2020\n",
        "\n",
        "Download the Covid19 dataset for Pakistan and save in your Google Drive (preferably)\n",
        "\n",
        "Load the data with Spark\n",
        "Save the copy in Parquet and ORC format\n",
        "Clean/transform the data if needed.\n",
        "Answer Below Questions\n",
        "Plot the cummulative Suspected Cases/Tests/Admitted/Deaths/Recovered/\n",
        "Group by cases based on States and other columns\n",
        "Find the mean and median cases per day across Pakistan and different states Plot them for better visualization.\n",
        "Perform other analysis as you may think contribute in your learning\n",
        "All these exercises must be done using Spark operations and submitted in Google colab notebook format through LMS.\n",
        "\n",
        "Due Date: 20:00 hrs 12/04/2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueu-yAPqLB8G"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5EHbjPhK87o"
      },
      "source": [
        "# Run below commands\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!ls spark-3.1.1-bin-hadoop3.2/bin\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qAi7X3lMG2B",
        "outputId": "c6557898-5c24-406e-f46d-ebe7645160fc"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beeline\t\t      pyspark\t\tspark-class.cmd   spark-sql\n",
            "beeline.cmd\t      pyspark2.cmd\tsparkR\t\t  spark-sql2.cmd\n",
            "docker-image-tool.sh  pyspark.cmd\tsparkR2.cmd\t  spark-sql.cmd\n",
            "find-spark-home       run-example\tsparkR.cmd\t  spark-submit\n",
            "find-spark-home.cmd   run-example.cmd\tspark-shell\t  spark-submit2.cmd\n",
            "load-spark-env.cmd    spark-class\tspark-shell2.cmd  spark-submit.cmd\n",
            "load-spark-env.sh     spark-class2.cmd\tspark-shell.cmd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsaZNdOmMIms"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd6niSQBMLCS",
        "outputId": "d5234e95-28dd-433a-9176-b67ee487b788"
      },
      "source": [
        "import findspark\n",
        "import pyspark\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .master(\"local[*]\")\\\n",
        "        .appName('week1_assignment') \\\n",
        "        .getOrCreate()\n",
        "# Test the spark \n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(100)])\n",
        "df.show(3, False)\n",
        "# Check the pyspark version\n",
        "print(pyspark.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n",
            "3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onY1BMCOM6RG",
        "outputId": "820ef996-5c6a-4f1f-bd17-f88d9b5a4a5b"
      },
      "source": [
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row\n",
        "df = spark.createDataFrame([\n",
        "    Row(aa=1, bb=2., cc='string1', dd=date(2000, 1, 1), ee=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(aa=2, bb=3., cc='string2', dd=date(2000, 2, 1), ee=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(aa=4, bb=5., cc='string3', dd=date(2000, 3, 1), ee=datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[aa: bigint, bb: double, cc: string, dd: date, ee: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}